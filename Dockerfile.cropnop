# syntax = docker/dockerfile:experimental
FROM pytorch/torchserve:0.8.2-cpu as base

USER root

FROM base as reqs
COPY gcp/inference_cropnop/requirements.txt requirements.txt
RUN pip3 install --upgrade pip
RUN pip install -r requirements.txt
COPY gcp/inference_utils.py /home/model-server/inference_utils.py

FROM reqs as build-torchserve
COPY gcp/inference_cropnop/handler.py /home/model-server
COPY model_weights/cropnop/*.pt /home/model-server

WORKDIR /home/model-server

RUN torch-model-archiver \
    --model-name cropnop \
    --version 1.0 \
    --serialized-file best_model.torchscript.pt \
    --handler handler.py \
    --export-path=model-store

CMD ["torchserve", "--start", "--ncs", "--model-store", "model-store", \
       "--models", "cropnop=cropnop.mar"]


