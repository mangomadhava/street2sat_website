{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJYsgRYq9tQR"
      },
      "source": [
        "# GoPro Photos to Crop KMZ\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/nasaharvest/street2sat/blob/main/notebooks/GoPro2CropKMZ.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "**Author**: Ivan Zvonkov\n",
        "\n",
        "**Last Modified**: Jul 8, 2024\n",
        "\n",
        "**Description**: Converts GoPro photos to crop type points. Specifically the notebook:\n",
        "\n",
        "1. Downloads GoPro photos from street2sat bucket.\n",
        "2. Create a dataframe from photos.\n",
        "3. Extract dates and coordinates.\n",
        "4. Classify as crop or not crop.\n",
        "5. Segment crops in crop photos.\n",
        "6. Filter out low confidence predictions.\n",
        "7. Move coordinate to field\n",
        "8. Get Admin Zones for each point\n",
        "9. Create KMZ file\n",
        "10. Save the notebook\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vsz6lpeBDfO"
      },
      "source": [
        "## Important Prerequisite\n",
        "\n",
        "Before running any cell in the notebook,\n",
        "1. Click the drop down triangle on the top right hand side and select \"Change Runtime Type\".\n",
        "2. Click the T4 radio button under Hardware Accelerator and click save.\n",
        "\n",
        "This will allow the CropSegmentation model to run much faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HooUu8spC4an"
      },
      "outputs": [],
      "source": [
        "# Required packages\n",
        "!pip install exifread utm simplekml earthengine-api geemap -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bInVS3VT96L3"
      },
      "source": [
        "## 1. Download GoPro photos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4ivKDDG9wzm"
      },
      "outputs": [],
      "source": [
        "# Login to Google Cloud, once you run this cell click on the space after \"browser:\" to enter the code\n",
        "!gcloud auth login\n",
        "# Your current project will be [None] and that is okay."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwZ1dCWH9pnS"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "GCLOUD_BUCKET = \"street2sat-uploaded\"\n",
        "\n",
        "# Specify the folder name and download the images\n",
        "GCLOUD_FOLDER = \"KENYA_v2/2022_07_13_Nakuru_2\"\n",
        "\n",
        "GCLOUD_PATH = f\"gs://{GCLOUD_BUCKET}/{GCLOUD_FOLDER}/\"\n",
        "PREFIX = GCLOUD_FOLDER.replace(\"/\", \"_\")\n",
        "Path(PREFIX).mkdir(exist_ok=True)\n",
        "print(f\"Ready to download images from {GCLOUD_PATH} to {PREFIX}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkjB7YhDGvur"
      },
      "outputs": [],
      "source": [
        "# Check amount of photos\n",
        "!gsutil du $GCLOUD_PATH | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXHDUZr-XygC"
      },
      "outputs": [],
      "source": [
        "# 20 mins for 10k images\n",
        "!gsutil -m cp -r $GCLOUD_PATH $PREFIX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjomcjvh_GJQ"
      },
      "source": [
        "## 2. Create dataframe from available photos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejFpnepF_OhO"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from shapely.geometry import Point\n",
        "from tqdm import tqdm\n",
        "\n",
        "import exifread\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mImhY-x--2j"
      },
      "outputs": [],
      "source": [
        "image_folder = Path(\"/content/KENYA_v2_2022_07_13_Nakuru_2/2022_07_13_Nakuru_2\")\n",
        "if (not image_folder.exists()):\n",
        "    print(\"STOP: Update image_folder to match the folder of images you downloaded\")\n",
        "else:\n",
        "    gopro_photo_paths = list(image_folder.glob(\"*.JPG\")) # May need to switch to .jpg\n",
        "    df = pd.DataFrame({\"paths\": gopro_photo_paths})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2tial6nxVZN"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaTYZA2q5J63"
      },
      "source": [
        "## 3. Extract date and coordinate from each available photo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2vDKktE2Rnw"
      },
      "outputs": [],
      "source": [
        "def extract_date_lat_lon(img_path):\n",
        "    img_bytes = open(img_path, \"rb\")\n",
        "    tags = exifread.process_file(img_bytes)\n",
        "    if tags == {}:\n",
        "        print(\"No exiftags found\")\n",
        "        return None, None, None\n",
        "\n",
        "    # Extract date\n",
        "    image_datetime = str(tags.get(\"Image DateTime\"))\n",
        "\n",
        "    # Convert to Python datetime object\n",
        "    dt = datetime.strptime(image_datetime, \"%Y:%m:%d %H:%M:%S\")\n",
        "\n",
        "    def convert_to_degrees(coord):\n",
        "        \"\"\" Convert the GPS coordinates stored in the EXIF to degress in float format\"\"\"\n",
        "        d = float(coord.values[0].num) / float(coord.values[0].den)\n",
        "        m = float(coord.values[1].num) / float(coord.values[1].den)\n",
        "        s = float(coord.values[2].num) / float(coord.values[2].den)\n",
        "        return d + (m / 60.0) + (s / 3600.0)\n",
        "\n",
        "    lat = convert_to_degrees(tags.get(\"GPS GPSLatitude\"))\n",
        "    lon = convert_to_degrees(tags.get(\"GPS GPSLongitude\"))\n",
        "\n",
        "    if tags.get(\"GPS GPSLatitudeRef\").values[0] != \"N\":\n",
        "        lat = 0 - lat\n",
        "    if tags.get(\"GPS GPSLongitudeRef\").values[0] != \"E\":\n",
        "        lon = 0 - lon\n",
        "\n",
        "    return dt, lat, lon\n",
        "\n",
        "# Extract date and lat lon from each image\n",
        "df[[\"date\", \"lat\", \"lon\"]] = df[\"paths\"].progress_apply(extract_date_lat_lon).to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-0eUxHMxkjf"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lg2jfzW5Gb6X"
      },
      "outputs": [],
      "source": [
        "gdf = gpd.GeoDataFrame(df, geometry=[Point(xy) for xy in zip(df[\"lon\"], df[\"lat\"])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tcfg_fStHOsI"
      },
      "outputs": [],
      "source": [
        "# TODO better point plotting\n",
        "\n",
        "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
        "region = world[world[\"name\"] == \"Kenya\"]\n",
        "ax = region.plot(facecolor=\"lightgray\", figsize=(15, 15));\n",
        "\n",
        "gdf.plot(\n",
        "    ax=ax,\n",
        "    marker='o',\n",
        "    categorical=True,\n",
        "    markersize=1,\n",
        "    #column=DATASET,\n",
        "    legend=True,\n",
        "    legend_kwds={'loc': 'lower left'});"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABTLSIrB5uxA"
      },
      "source": [
        "## 4. Classify as crop or not crop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoZtQs26AWd2"
      },
      "outputs": [],
      "source": [
        "# Download CropNop model weights\n",
        "!gsutil cp gs://street2sat-models/cropnop_v1.torchscript.pt ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bdrloc9ELb_3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load CropNop model\n",
        "cropnop_model = torch.jit.load(\"/content/cropnop_v1.torchscript.pt\")\n",
        "\n",
        "def is_crop_or_not(img_path):\n",
        "\n",
        "    # Preprocess image\n",
        "    img = plt.imread(img_path)\n",
        "    img = cv2.resize(img, (300, 300)) / 255\n",
        "    img = img.transpose(2, 0, 1).astype(\"float32\")\n",
        "    img_tensor = torch.from_numpy(img).float().to(device)\n",
        "\n",
        "    # Make crop or not prediction\n",
        "    output = cropnop_model(img_tensor.unsqueeze(0))\n",
        "    is_crop = (output <= 0).item()\n",
        "    return is_crop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkNtpAaezZkA"
      },
      "outputs": [],
      "source": [
        "# CropNop Example\n",
        "img_path = df[\"paths\"].loc[8]\n",
        "is_crop_prediction = is_crop_or_not(img_path)\n",
        "\n",
        "plt.imshow(plt.imread(img_path))\n",
        "print(f\"CropNop Model Prediction: {'Crop' if is_crop_prediction else 'Not crop'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bdd1H2WA-TTf"
      },
      "outputs": [],
      "source": [
        "# 20 mins for 10k images\n",
        "df[\"is_crop\"] = df[\"paths\"].progress_apply(is_crop_or_not)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dA4L55Eq32J"
      },
      "outputs": [],
      "source": [
        "df[\"is_crop\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qK8Hbkesmp5o"
      },
      "source": [
        "## 5. Segment crops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAywn-2rApRi"
      },
      "outputs": [],
      "source": [
        "# Download CropSeg model weights\n",
        "!gsutil cp gs://street2sat-models/cropseg_v1.torchscript.pt ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4nMP3OTnYcN"
      },
      "outputs": [],
      "source": [
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "os.environ[\"LRU_CACHE_CAPACITY\"] = \"1\"\n",
        "\n",
        "# Load CropSeg model\n",
        "cropseg_model = torch.jit.load(\"/content/cropseg_v1.torchscript.pt\")\n",
        "\n",
        "CLASSES = [\n",
        "    \"background\",\n",
        "    \"banana\",\n",
        "    \"maize\",\n",
        "    \"rice\",\n",
        "    \"soybean\",\n",
        "    \"sugarcane\",\n",
        "    \"sunflower\",\n",
        "    \"tobacco\",\n",
        "    \"wheat\",\n",
        "]\n",
        "\n",
        "def segment_crops(img_path):\n",
        "    img = imread(img_path)\n",
        "    img = resize(img, (800, 800))\n",
        "    img = img.astype(float)\n",
        "    img = (\n",
        "        255 * (img - np.min(img[:])) / (np.max(img[:]) - np.min(img[:]) + 0.1)\n",
        "    ).astype(float)\n",
        "    img = (img + 0.5) / 256\n",
        "    gamma = -1 / np.nanmean(np.log(img))\n",
        "    img = img ** (gamma)\n",
        "    img_transposed = img.transpose(2, 0, 1).astype(\"float32\")\n",
        "    img_tensor = torch.from_numpy(img_transposed).unsqueeze(0).to(device)\n",
        "    return img, cropseg_model(img_tensor)[0].cpu().detach().numpy()\n",
        "\n",
        "\n",
        "def segment_crops_w_proportions(img_path):\n",
        "    _, output = segment_crops(img_path)\n",
        "    image_size = output.shape[1] * output.shape[2]\n",
        "    segmentation_proportions = {\n",
        "        crop:  round(output[i].sum() / image_size, 4) for i, crop in enumerate(CLASSES)\n",
        "    }\n",
        "    return segmentation_proportions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69wTYsp23Acl"
      },
      "outputs": [],
      "source": [
        "df_crops = df[df['is_crop']].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jnsCRlV9Ym-"
      },
      "outputs": [],
      "source": [
        "# Example CropSeg Predictions\n",
        "img_path = df_crops[\"paths\"].iloc[0]\n",
        "img, output = segment_crops(img_path)\n",
        "props = segment_crops_w_proportions(img_path)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 12))\n",
        "axes[0].imshow(img)\n",
        "axes[1].imshow(output.argmax(axis=0), cmap='tab10', vmin=0, vmax=len(CLASSES))\n",
        "for crop, prop in sorted(props.items(), key=lambda item: item[1], reverse=True):\n",
        "    if crop != \"background\" and prop > 0:\n",
        "        print(f\"{crop}: {prop}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOkOJViQq1lR"
      },
      "outputs": [],
      "source": [
        "# ~10 mins for 500 images, 1hr for 2k images\n",
        "# TODO can probably make predictions faster through batches\n",
        "df_crops[\"segmentation_proportions\"] = df_crops[\"paths\"].progress_apply(segment_crops_w_proportions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLPMV57Ap9cV"
      },
      "outputs": [],
      "source": [
        "proportion_columns = pd.json_normalize(df_crops[\"segmentation_proportions\"]).set_index(df_crops.index)\n",
        "df_crop_prop = pd.concat([df_crops, proportion_columns], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmgUgQaaRvLM"
      },
      "outputs": [],
      "source": [
        "crops = list(proportion_columns.columns[1:][1:])\n",
        "if \"dominant_crop\" not in df_crop_prop.columns:\n",
        "    df_crop_prop[\"dominant_crop\"] = df_crop_prop[crops].apply(lambda x: max(dict(x), key=dict(x).get), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7OK7kXjxpH8"
      },
      "source": [
        "## 6. Filter out low confidence predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB0HTfPDuM_-"
      },
      "outputs": [],
      "source": [
        "print(f\"Before background filter: {len(df_crop_prop)}\")\n",
        "\n",
        "# Only points with less than 95% background kept\n",
        "bg_threshold = 0.95\n",
        "df_crops_filtered = df_crop_prop[df_crop_prop[\"background\"] < bg_threshold ].copy()\n",
        "print(f\"After background filter: {len(df_crops_filtered)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfYD0VtGE_6e"
      },
      "source": [
        "## 7. Move coordinate to field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2t19_SAFmw6"
      },
      "outputs": [],
      "source": [
        "import utm\n",
        "from datetime import timedelta\n",
        "import math\n",
        "\n",
        "# TODO add visual example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIjwO4TsFlme"
      },
      "outputs": [],
      "source": [
        "# Copied and pasted from field_coord_distance_offset.ipynb\n",
        "\n",
        "floor10 = lambda x: x//10 * 10\n",
        "to_pixel_centroid = lambda coord: (floor10(coord[0]) + 5, floor10(coord[1]) + 5)\n",
        "\n",
        "def generate_offset_point_wgs84(coord0, coord1, is_right_hand_drive=True, meters=20):\n",
        "    utm_coord0 = utm.from_latlon(coord0[0], coord0[1])\n",
        "    utm_coord1 = utm.from_latlon(coord1[0], coord1[1])\n",
        "\n",
        "    for i, zone_type in [(2, \"number\"), (3, \"letter\")]:\n",
        "        if utm_coord1[i] != utm_coord0[i]:\n",
        "            print(utm_coord0)\n",
        "            print(utm_coord1)\n",
        "            raise ValueError(f\"UTM Zone {zone_type} mismatch: {utm_coord0[i]} and {utm_coord1[i]}\")\n",
        "\n",
        "\n",
        "    delta_east = utm_coord1[0] - utm_coord0[0]\n",
        "    delta_north = utm_coord1[1] - utm_coord0[1]\n",
        "\n",
        "    # Offset for meters change in offset point distance\n",
        "    x_offset = np.abs(meters * math.cos(math.atan(delta_east / delta_north)))\n",
        "\n",
        "    # Direction of offset\n",
        "    x_direction = np.sign(delta_north) if is_right_hand_drive else -np.sign(delta_north)\n",
        "    x_offset *= x_direction\n",
        "\n",
        "    orthogonal_slope = -delta_east / delta_north\n",
        "    orthogonal_b = utm_coord1[1] - (orthogonal_slope * utm_coord1[0])\n",
        "    orthogonal_y = lambda x: orthogonal_slope*x + orthogonal_b\n",
        "\n",
        "    field_point_x = utm_coord1[0] + x_offset\n",
        "    field_point_y = orthogonal_y(field_point_x)\n",
        "\n",
        "    field_latlon = utm.to_latlon(field_point_x, field_point_y, utm_coord1[2], utm_coord1[3])\n",
        "\n",
        "    pixel_centroid_x, pixel_centroid_y  = to_pixel_centroid((field_point_x, field_point_y))\n",
        "    pixel_centroid_field_latlon = utm.to_latlon(pixel_centroid_x, pixel_centroid_y, utm_coord1[2], utm_coord1[3])\n",
        "\n",
        "    return field_latlon, pixel_centroid_field_latlon, (delta_east, delta_north)\n",
        "\n",
        "def road_pixel_centroid(coord):\n",
        "    utm_coord = utm.from_latlon(coord[0], coord[1])\n",
        "    utm_pixel_centroid = to_pixel_centroid(utm_coord)\n",
        "    return utm.to_latlon(*utm_pixel_centroid, utm_coord[2], utm_coord[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNF0Z9woE-TS"
      },
      "outputs": [],
      "source": [
        "field_points = []\n",
        "is_right_hand_drive = False\n",
        "\n",
        "for i in tqdm(range(0, len(df_crops_filtered))):\n",
        "\n",
        "    # Get road coordinate\n",
        "    current_record = df_crops_filtered.iloc[i]\n",
        "    road_coord = current_record[\"lat\"], current_record[\"lon\"]\n",
        "    road_10m_centroid = road_pixel_centroid(road_coord)\n",
        "\n",
        "    # Get prior coordinate\n",
        "    time1 = current_record[\"date\"]\n",
        "    before_time_interval = time1 - timedelta(seconds=10)\n",
        "    time_filter = (df[\"date\"] < str(time1)) & (df[\"date\"] > str(before_time_interval))\n",
        "    prior_records = df[time_filter].sort_values(by=['date'])\n",
        "    if len(prior_records) == 0:\n",
        "        print(f\"No prior records found for {i}\")\n",
        "        continue\n",
        "\n",
        "    prior_record = prior_records.iloc[-1]\n",
        "    prior_coord = prior_record[\"lat\"], prior_record[\"lon\"]\n",
        "\n",
        "    # Get direction and field offset\n",
        "    try:\n",
        "        output = generate_offset_point_wgs84(prior_coord, road_coord, is_right_hand_drive)\n",
        "        offset_field_coord, offset_field_pixel_centroid, driving_direction = output\n",
        "\n",
        "        field_points.append({\n",
        "            \"road_pixel_centroid\": road_10m_centroid,\n",
        "            \"is_right_hand_drive\": is_right_hand_drive,\n",
        "            \"driving_easting\": driving_direction[0],\n",
        "            \"driving_northing\": driving_direction[1],\n",
        "            \"offset_field_coord\": offset_field_coord,\n",
        "            \"offset_field_pixel_centroid\": offset_field_pixel_centroid,\n",
        "            \"time_computed\": datetime.now(),\n",
        "            **df_crops_filtered.iloc[i],\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"Index: {i}, Exception: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGlXFH6VCzqN"
      },
      "outputs": [],
      "source": [
        "df_crop_type_w_duplicates = pd.DataFrame(field_points)\n",
        "print(f\"Points BEFORE deduplicating: {len(df_crop_type_w_duplicates)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXcHf7hx8Nb4"
      },
      "outputs": [],
      "source": [
        "# Deduplication by selecting max dominant crop\n",
        "def get_max_dominant_crop(group):\n",
        "  max_idx = group.apply(lambda x: x[x['dominant_crop']], axis=1).idxmax()\n",
        "  return group.loc[max_idx]\n",
        "\n",
        "# create new DataFrame with no duplicate - using groupby and applying get_max_dominant_crop on each group\n",
        "df_crop_type = df_crop_type_w_duplicates.groupby('offset_field_pixel_centroid').apply(get_max_dominant_crop).reset_index(drop=True)\n",
        "print(f\"Points AFTER deduplicating: {len(df_crop_type)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5_B17ZCGjLY"
      },
      "source": [
        "## 8. Get Admin Zones for each point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flW3oJHzpgE0"
      },
      "outputs": [],
      "source": [
        "# Obtain Admin Boundaries from GADM: https://gadm.org/data.html\n",
        "gdf_gadm2 = gpd.read_file(\"https://geodata.ucdavis.edu/gadm/gadm4.1/json/gadm41_KEN_2.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oh8W4SlKq1Jc"
      },
      "outputs": [],
      "source": [
        "geometry = [Point(xy) for xy in zip(df_crop_type[\"lon\"], df_crop_type[\"lat\"])]\n",
        "gdf_points = gpd.GeoDataFrame(df_crop_type, geometry=geometry, crs=\"EPSG:4326\")\n",
        "gdf_points_gadm2 = gpd.sjoin(gdf_points, gdf_gadm2, how='left', op='within')\n",
        "\n",
        "df_crop_type[\"GADM1\"] = gdf_points_gadm2[\"NAME_1\"]\n",
        "df_crop_type[\"GADM2\"] = gdf_points_gadm2[\"NAME_2\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqHgbBVTtgcQ"
      },
      "outputs": [],
      "source": [
        "df_crop_type[\"GADM1\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It6A6pb2u9e7"
      },
      "outputs": [],
      "source": [
        "df_crop_type[\"GADM2\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH4t_u1SMkG0"
      },
      "source": [
        "## 9. Create KMZ file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9F5fUCHgMv7o"
      },
      "outputs": [],
      "source": [
        "import simplekml\n",
        "\n",
        "DATA_GADM1_ZONES =  \"_\".join(df_crop_type[\"GADM1\"].unique())\n",
        "if DATA_GADM1_ZONES not in PREFIX:\n",
        "    PREFIX += f\"_{DATA_GADM1_ZONES}\"\n",
        "\n",
        "DATA_YEARS = \"_\".join([str(year) for year in df_crop_type[\"date\"].dt.year.unique()])\n",
        "if DATA_YEARS not in PREFIX:\n",
        "    PREFIX += f\"_{DATA_YEARS}\"\n",
        "\n",
        "DATA_BG_THRESHOLD = f\"bg{int(bg_threshold*100)}\"\n",
        "PREFIX += f\"_{DATA_BG_THRESHOLD}\"\n",
        "\n",
        "# Change if necessary\n",
        "PREFIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umpd_qNZGQkW"
      },
      "outputs": [],
      "source": [
        "endpoint_prefix = GCLOUD_PATH.replace(\"gs://\", \"\")\n",
        "\n",
        "\n",
        "def create_description(record, image_path):\n",
        "    image_name = Path(image_path).name\n",
        "    endpoint = Path(endpoint_prefix + \"/\" + image_name)\n",
        "    name = \"-\".join(endpoint.parts[2:-1]) + \"-\" + endpoint.stem\n",
        "    return f\"\"\"\n",
        "<img src='files/{image_name}' width='900px'/>\n",
        "<br/>\n",
        "<h2>{name}</h2>\n",
        "<p>Capture Time: {record['date']}</p>\n",
        "<a href='https://storage.cloud.google.com/{endpoint}'>\n",
        "    https://storage.cloud.google.com/{endpoint}\n",
        "</a>\n",
        "\n",
        "<h2>Location</h2>\n",
        "<p>GADM1: {record['GADM1']}</p>\n",
        "<p>GADM2: {record['GADM2']}</p>\n",
        "<p>Road Lat Lon: {record['lat']}, {record['lon']}</p>\n",
        "<p>Field Lat Lon:  {record[\"offset_field_pixel_centroid\"]}</p>\n",
        "\n",
        "\n",
        "<h2>Driving Direction</h2>\n",
        "<p>Northing: {record['driving_northing']}</p>\n",
        "<p>Easting: {record['driving_easting']}</p>\n",
        "<p>Is Right Hand Drive: {record['is_right_hand_drive']}</p>\n",
        "\n",
        "<h2>CropSeg Model Prediction</h2>\n",
        "<p>{record['segmentation_proportions']}</p>\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uULyghOYM4nR"
      },
      "outputs": [],
      "source": [
        "# Create KMZ file for every 100 points (more points make the KMZ laggy)\n",
        "num_records = len(df_crop_type)\n",
        "\n",
        "for range_start in range(0, num_records, 100):\n",
        "    if range_start + 100 < num_records:\n",
        "        range_end = range_start + 100\n",
        "    else:\n",
        "        range_end = num_records\n",
        "\n",
        "    kml_document_name = PREFIX + f\"_{range_start}_{range_end}\"\n",
        "\n",
        "    kml = simplekml.Kml()\n",
        "    kml.document.name = kml_document_name\n",
        "\n",
        "    for _, record in tqdm(df_crop_type[range_start:range_end].iterrows()):\n",
        "        latlon = record[\"offset_field_pixel_centroid\"]\n",
        "        image_path = record['paths']\n",
        "        kml.newpoint(\n",
        "            coords=[(latlon[1], latlon[0])],  # lon, lat optional height\n",
        "            description=create_description(record, image_path),\n",
        "            name=record[\"dominant_crop\"],\n",
        "            timestamp=record[\"date\"]\n",
        "        )\n",
        "        kml.addfile(image_path)\n",
        "\n",
        "\n",
        "    kml.savekmz(f\"{kml_document_name}.kmz\", format=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsn54H7aCGEu"
      },
      "outputs": [],
      "source": [
        "# Upload KMZ files to my Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp -r /content/*.kmz /content/gdrive/My\\ Drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbWMG0F3XSnV"
      },
      "source": [
        "The uploaded KMZ files can now be downloaded onto a computer with Google Earth Pro.\n",
        "\n",
        "A Quality Assessment must be conducted following this protocol:\n",
        "\n",
        "https://docs.google.com/document/d/1OCF2gpCQQbZP-y6xcTbKE2OzhkxMtyaJi8wiWi8jfzs/edit?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkkkCjuaVOBN"
      },
      "source": [
        "## 10. Save the notebook\n",
        "\n",
        "1. Click File / Download / Download .ipynb\n",
        "2. Rename this notebook to have the name: ` <PREFIX>.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzoQ9Y2dmK76"
      },
      "outputs": [],
      "source": [
        "print(f\"Suggested notebook name: {PREFIX}.ipynb\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
