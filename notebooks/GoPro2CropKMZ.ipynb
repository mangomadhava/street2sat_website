{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GoPro Photos to Crop KMZ\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/nasaharvest/street2sat/blob/gopro2crop/notebooks/GoPro2CropKMZ.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "**Author**: Ivan Zvonkov\n",
        "\n",
        "**Last Modified**: May 20, 2024\n",
        "\n",
        "**Description**: Converts GoPro photos to crop type points. Specifically the notebook:\n",
        "\n",
        "1. Downloads GoPro photos from street2sat bucket.\n",
        "2. Create a dataframe from photos.\n",
        "3. Extract dates and coordinates.\n",
        "4. Classify as crop or not crop.\n",
        "5. Segment crops in crop photos.\n",
        "6. Filter out low confidence predictions.\n",
        "7. Move coordinate to field\n",
        "8. Get Admin Zones for each point\n",
        "9. Create KMZ file\n",
        "10. Save the notebook\n",
        "11. Download KMZ files\n"
      ],
      "metadata": {
        "id": "jJYsgRYq9tQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Important Prerequisite\n",
        "\n",
        "Before running any cell in the notebook,\n",
        "1. Click the drop down triangle on the top right hand side and select \"Change Runtime Type\".\n",
        "2. Click the T4 radio button under Hardware Accelerator and click save.\n",
        "\n",
        "This will allow the CropSegmentation model to run much faster."
      ],
      "metadata": {
        "id": "1vsz6lpeBDfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required packages\n",
        "!pip install exifread utm simplekml earthengine-api geemap -q"
      ],
      "metadata": {
        "id": "HooUu8spC4an"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Download GoPro photos"
      ],
      "metadata": {
        "id": "bInVS3VT96L3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Login to Google Cloud\n",
        "!gcloud auth login"
      ],
      "metadata": {
        "id": "B4ivKDDG9wzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwZ1dCWH9pnS"
      },
      "outputs": [],
      "source": [
        "# Specify the folder name and download the images\n",
        "STREET2SAT_UPLOADED_FOLDER = \"gs://street2sat-uploaded/KENYA_v2/2021-07-05-T1\"\n",
        "!gsutil -m cp -r $STREET2SAT_UPLOADED_FOLDER ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create dataframe from available photos"
      ],
      "metadata": {
        "id": "gjomcjvh_GJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from shapely.geometry import Point\n",
        "from tqdm import tqdm\n",
        "\n",
        "import exifread\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "\n",
        "tqdm.pandas()"
      ],
      "metadata": {
        "id": "ejFpnepF_OhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = Path(\"/content/2021-07-05-T1\")\n",
        "if (not image_folder.exists()):\n",
        "    print(\"STOP: Update image_folder to match the folder of images you downloaded\")\n",
        "else:\n",
        "    gopro_photo_paths = list(image_folder).glob(\"*.JPG\")\n",
        "    df = pd.DataFrame({\"paths\": gopro_photo_paths})"
      ],
      "metadata": {
        "id": "-mImhY-x--2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Extract date and coordinate from each available photo"
      ],
      "metadata": {
        "id": "SaTYZA2q5J63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_date_lat_lon(img_path):\n",
        "    img_bytes = open(img_path, \"rb\")\n",
        "    tags = exifread.process_file(img_bytes)\n",
        "    if tags == {}:\n",
        "        print(\"No exiftags found\")\n",
        "        return None, None, None\n",
        "\n",
        "    # Extract date\n",
        "    image_datetime = str(tags.get(\"Image DateTime\"))\n",
        "\n",
        "    # Convert to Python datetime object\n",
        "    dt = datetime.strptime(image_datetime, \"%Y:%m:%d %H:%M:%S\")\n",
        "\n",
        "    def convert_to_degrees(coord):\n",
        "        \"\"\" Convert the GPS coordinates stored in the EXIF to degress in float format\"\"\"\n",
        "        d = float(coord.values[0].num) / float(coord.values[0].den)\n",
        "        m = float(coord.values[1].num) / float(coord.values[1].den)\n",
        "        s = float(coord.values[2].num) / float(coord.values[2].den)\n",
        "        return d + (m / 60.0) + (s / 3600.0)\n",
        "\n",
        "    lat = convert_to_degrees(tags.get(\"GPS GPSLatitude\"))\n",
        "    lon = convert_to_degrees(tags.get(\"GPS GPSLongitude\"))\n",
        "\n",
        "    if tags.get(\"GPS GPSLatitudeRef\").values[0] != \"N\":\n",
        "        lat = 0 - lat\n",
        "    if tags.get(\"GPS GPSLongitudeRef\").values[0] != \"E\":\n",
        "        lon = 0 - lon\n",
        "\n",
        "    return dt, lat, lon\n",
        "\n",
        "# Extract date and lat lon from each image\n",
        "df[[\"date\", \"lat\", \"lon\"]] = df[\"paths\"].progress_apply(extract_date_lat_lon).to_list()"
      ],
      "metadata": {
        "id": "G2vDKktE2Rnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf = gpd.GeoDataFrame(df, geometry=[Point(xy) for xy in zip(df[\"lon\"], df[\"lat\"])])"
      ],
      "metadata": {
        "id": "Lg2jfzW5Gb6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO better point plotting\n",
        "\n",
        "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
        "region = world[world[\"name\"] == \"Kenya\"]\n",
        "ax = region.plot(facecolor=\"lightgray\", figsize=(15, 15));\n",
        "\n",
        "gdf.plot(\n",
        "    ax=ax,\n",
        "    marker='o',\n",
        "    categorical=True,\n",
        "    markersize=1,\n",
        "    #column=DATASET,\n",
        "    legend=True,\n",
        "    legend_kwds={'loc': 'lower left'});"
      ],
      "metadata": {
        "id": "Tcfg_fStHOsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Classify as crop or not crop"
      ],
      "metadata": {
        "id": "ABTLSIrB5uxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download CropNop model weights\n",
        "!gsutil cp gs://street2sat-models/cropnop_v1.torchscript.pt ."
      ],
      "metadata": {
        "id": "CoZtQs26AWd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Load CropNop model\n",
        "cropnop_model = torch.jit.load(\"/content/cropnop_v1.torchscript.pt\")\n",
        "\n",
        "def is_crop_or_not(img_path):\n",
        "\n",
        "    # Preprocess image\n",
        "    img = plt.imread(img_path)\n",
        "    img = cv2.resize(img, (300, 300)) / 255\n",
        "    img = img.transpose(2, 0, 1).astype(\"float32\")\n",
        "    img_tensor = torch.from_numpy(img).float().to(device)\n",
        "\n",
        "    # Make crop or not prediction\n",
        "    output = cropnop_model(img_tensor.unsqueeze(0))\n",
        "    is_crop = (output <= 0).item()\n",
        "    return is_crop"
      ],
      "metadata": {
        "id": "Bdrloc9ELb_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CropNop Example\n",
        "img_path = df[\"paths\"].loc[8]\n",
        "is_crop_prediction = is_crop_or_not(img_path)\n",
        "\n",
        "plt.imshow(plt.imread(img_path))\n",
        "print(f\"CropNop Model Prediction: {'Crop' if is_crop_prediction else 'Not crop'}\")"
      ],
      "metadata": {
        "id": "SkNtpAaezZkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"is_crop\"] = df[\"paths\"].progress_apply(is_crop_or_not)"
      ],
      "metadata": {
        "id": "Bdd1H2WA-TTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"is_crop\"].value_counts()"
      ],
      "metadata": {
        "id": "9dA4L55Eq32J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Segment crops"
      ],
      "metadata": {
        "id": "qK8Hbkesmp5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download CropSeg model weights\n",
        "!gsutil cp gs://street2sat-models/cropseg_v1.torchscript.pt ."
      ],
      "metadata": {
        "id": "aAywn-2rApRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "os.environ[\"LRU_CACHE_CAPACITY\"] = \"1\"\n",
        "\n",
        "# Load CropSeg model\n",
        "cropseg_model = torch.jit.load(\"/content/cropseg_v1.torchscript.pt\")\n",
        "\n",
        "CLASSES = [\n",
        "    \"background\",\n",
        "    \"banana\",\n",
        "    \"maize\",\n",
        "    \"rice\",\n",
        "    \"soybean\",\n",
        "    \"sugarcane\",\n",
        "    \"sunflower\",\n",
        "    \"tobacco\",\n",
        "    \"wheat\",\n",
        "]\n",
        "\n",
        "def segment_crops(img_path):\n",
        "    img = imread(img_path)\n",
        "    img = resize(img, (800, 800))\n",
        "    img = img.astype(float)\n",
        "    img = (\n",
        "        255 * (img - np.min(img[:])) / (np.max(img[:]) - np.min(img[:]) + 0.1)\n",
        "    ).astype(float)\n",
        "    img = (img + 0.5) / 256\n",
        "    gamma = -1 / np.nanmean(np.log(img))\n",
        "    img = img ** (gamma)\n",
        "    img_transposed = img.transpose(2, 0, 1).astype(\"float32\")\n",
        "    img_tensor = torch.from_numpy(img_transposed).unsqueeze(0).to(device)\n",
        "    return img, cropseg_model(img_tensor)[0].cpu().detach().numpy()\n",
        "\n",
        "\n",
        "def segment_crops_w_proportions(img_path):\n",
        "    _, output = segment_crops(img_path)\n",
        "    image_size = output.shape[1] * output.shape[2]\n",
        "    segmentation_proportions = {\n",
        "        crop:  round(output[i].sum() / image_size, 4) for i, crop in enumerate(CLASSES)\n",
        "    }\n",
        "    return segmentation_proportions"
      ],
      "metadata": {
        "id": "T4nMP3OTnYcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_crops = df[df['is_crop']].copy()"
      ],
      "metadata": {
        "id": "69wTYsp23Acl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example CropSeg Predictions\n",
        "img_path = df_crops[\"paths\"].loc[8]\n",
        "img, output = segment_crops(img_path)\n",
        "props = segment_crops_w_proportions(img_path)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 12))\n",
        "axes[0].imshow(img)\n",
        "axes[1].imshow(output.argmax(axis=0), cmap='tab10', vmin=0, vmax=len(CLASSES))\n",
        "for crop, prop in sorted(props.items(), key=lambda item: item[1], reverse=True):\n",
        "    if crop != \"background\" and prop > 0:\n",
        "        print(f\"{crop}: {prop}\")"
      ],
      "metadata": {
        "id": "-jnsCRlV9Ym-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ~10 mins for 500 images\n",
        "# TODO can probably make predictions faster through batches\n",
        "df_crops[\"segmentation_proportions\"] = df_crops[\"paths\"].progress_apply(segment_crops_w_proportions)"
      ],
      "metadata": {
        "id": "gOkOJViQq1lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proportion_columns = pd.json_normalize(df_crops[\"segmentation_proportions\"]).set_index(df_crops.index)\n",
        "df_crop_prop = pd.concat([df_crops, proportion_columns], axis=1)"
      ],
      "metadata": {
        "id": "XLPMV57Ap9cV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crops = list(proportion_columns.columns[1:][1:])\n",
        "if \"dominant_crop\" not in df_crop_prop.columns:\n",
        "    df_crop_prop[\"dominant_crop\"] = df_crop_prop[crops].apply(lambda x: max(dict(x), key=dict(x).get), axis=1)"
      ],
      "metadata": {
        "id": "LmgUgQaaRvLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Filter out low confidence predictions"
      ],
      "metadata": {
        "id": "l7OK7kXjxpH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Before background filter: {len(df_crop_prop)}\")\n",
        "\n",
        "# Only points with less than 95% background kept\n",
        "df_crops_filtered = df_crop_prop[df_crop_prop[\"background\"] < 0.95 ].copy()\n",
        "print(f\"After background filter: {len(df_crops_filtered)}\")\n"
      ],
      "metadata": {
        "id": "CB0HTfPDuM_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Move coordinate to field"
      ],
      "metadata": {
        "id": "CfYD0VtGE_6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import utm\n",
        "from datetime import timedelta\n",
        "import math\n",
        "\n",
        "# TODO add visual example"
      ],
      "metadata": {
        "id": "u2t19_SAFmw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copied and pasted from field_coord_distance_offset.ipynb\n",
        "\n",
        "floor10 = lambda x: x//10 * 10\n",
        "to_pixel_centroid = lambda coord: (floor10(coord[0]) + 5, floor10(coord[1]) + 5)\n",
        "\n",
        "def generate_offset_point_wgs84(coord0, coord1, is_right_hand_drive=True, meters=20):\n",
        "    utm_coord0 = utm.from_latlon(coord0[0], coord0[1])\n",
        "    utm_coord1 = utm.from_latlon(coord1[0], coord1[1])\n",
        "\n",
        "    for i, zone_type in [(2, \"number\"), (3, \"letter\")]:\n",
        "        if utm_coord1[i] != utm_coord0[i]:\n",
        "            print(utm_coord0)\n",
        "            print(utm_coord1)\n",
        "            raise ValueError(f\"UTM Zone {zone_type} mismatch: {utm_coord0[i]} and {utm_coord1[i]}\")\n",
        "\n",
        "\n",
        "    delta_east = utm_coord1[0] - utm_coord0[0]\n",
        "    delta_north = utm_coord1[1] - utm_coord0[1]\n",
        "\n",
        "    # Offset for meters change in offset point distance\n",
        "    x_offset = np.abs(meters * math.cos(math.atan(delta_east / delta_north)))\n",
        "\n",
        "    # Direction of offset\n",
        "    x_direction = np.sign(delta_north) if is_right_hand_drive else -np.sign(delta_north)\n",
        "    x_offset *= x_direction\n",
        "\n",
        "    orthogonal_slope = -delta_east / delta_north\n",
        "    orthogonal_b = utm_coord1[1] - (orthogonal_slope * utm_coord1[0])\n",
        "    orthogonal_y = lambda x: orthogonal_slope*x + orthogonal_b\n",
        "\n",
        "    field_point_x = utm_coord1[0] + x_offset\n",
        "    field_point_y = orthogonal_y(field_point_x)\n",
        "\n",
        "    field_latlon = utm.to_latlon(field_point_x, field_point_y, utm_coord1[2], utm_coord1[3])\n",
        "\n",
        "    pixel_centroid_x, pixel_centroid_y  = to_pixel_centroid((field_point_x, field_point_y))\n",
        "    pixel_centroid_field_latlon = utm.to_latlon(pixel_centroid_x, pixel_centroid_y, utm_coord1[2], utm_coord1[3])\n",
        "\n",
        "    return field_latlon, pixel_centroid_field_latlon, (delta_east, delta_north)\n",
        "\n",
        "def road_pixel_centroid(coord):\n",
        "    utm_coord = utm.from_latlon(coord[0], coord[1])\n",
        "    utm_pixel_centroid = to_pixel_centroid(utm_coord)\n",
        "    return utm.to_latlon(*utm_pixel_centroid, utm_coord[2], utm_coord[3])"
      ],
      "metadata": {
        "id": "SIjwO4TsFlme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "field_points = []\n",
        "is_right_hand_drive = False\n",
        "\n",
        "for i in tqdm(range(0, len(df_crops_filtered))):\n",
        "\n",
        "    # Get road coordinate\n",
        "    current_record = df_crops_filtered.iloc[i]\n",
        "    road_coord = current_record[\"lat\"], current_record[\"lon\"]\n",
        "    road_10m_centroid = road_pixel_centroid(road_coord)\n",
        "\n",
        "    # Get prior coordinate\n",
        "    time1 = current_record[\"date\"]\n",
        "    before_time_interval = time1 - timedelta(seconds=10)\n",
        "    time_filter = (df[\"date\"] < str(time1)) & (df[\"date\"] > str(before_time_interval))\n",
        "    prior_records = df[time_filter].sort_values(by=['date'])\n",
        "    if len(prior_records) == 0:\n",
        "        print(f\"No prior records found for {i}\")\n",
        "        continue\n",
        "\n",
        "    prior_record = prior_records.iloc[-1]\n",
        "    prior_coord = prior_record[\"lat\"], prior_record[\"lon\"]\n",
        "\n",
        "    # Get direction and field offset\n",
        "    output = generate_offset_point_wgs84(prior_coord, road_coord, is_right_hand_drive)\n",
        "    offset_field_coord, offset_field_pixel_centroid, driving_direction = output\n",
        "\n",
        "    field_points.append({\n",
        "        \"road_pixel_centroid\": road_10m_centroid,\n",
        "        \"is_right_hand_drive\": is_right_hand_drive,\n",
        "        \"driving_easting\": driving_direction[0],\n",
        "        \"driving_northing\": driving_direction[1],\n",
        "        \"offset_field_coord\": offset_field_coord,\n",
        "        \"offset_field_pixel_centroid\": offset_field_pixel_centroid,\n",
        "        \"time_computed\": datetime.now(),\n",
        "        **df_crops_filtered.iloc[i],\n",
        "    })\n"
      ],
      "metadata": {
        "id": "sNF0Z9woE-TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_crop_type = pd.DataFrame(field_points)"
      ],
      "metadata": {
        "id": "rGlXFH6VCzqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Get Admin Zones for each point"
      ],
      "metadata": {
        "id": "c5_B17ZCGjLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ee\n",
        "import geemap\n",
        "\n",
        "ee.Authenticate()"
      ],
      "metadata": {
        "id": "Ya-eyyKrKinw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_NAME = \"bsos-geog-harvest1\" # You may need to change this to match your GEE project\n",
        "ee.Initialize(project=PROJECT_NAME)"
      ],
      "metadata": {
        "id": "i9jpJMi2K5t2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "admin_level2_fc = ee.FeatureCollection(\"FAO/GAUL/2015/level2\")\n",
        "adm1_image = admin_level2_fc.reduceToImage(ee.List([f'ADM1_CODE']), ee.Reducer.mean())\n",
        "adm2_image = admin_level2_fc.reduceToImage(ee.List([f'ADM2_CODE']), ee.Reducer.mean())"
      ],
      "metadata": {
        "id": "pL8cCDZeLMkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = 0\n",
        "adm1_list = []\n",
        "adm2_list = []\n",
        "\n",
        "def ee_feature_from_row(coord):\n",
        "    return ee.Feature(ee.Geometry.Point(coord[1], coord[0]), {})\n",
        "\n",
        "# Loop necessary so ee_to_gdf doesn't time out\n",
        "for i in tqdm(range(0, len(df_crop_type), 1000)):\n",
        "    ee_fc = ee.FeatureCollection(df_crop_type.iloc[i:i+1000][\"offset_field_pixel_centroid\"].apply(ee_feature_from_row).to_list())\n",
        "    # Using small scale=10 to ensure most points don't fall between boundaries\n",
        "    ee_points_adm1 = adm1_image.sampleRegions(collection=ee_fc, scale=10)\n",
        "    ee_points_adm2 = adm2_image.sampleRegions(collection=ee_fc, scale=10)\n",
        "    adm1_list += geemap.ee_to_gdf(ee_points_adm1)[\"mean\"].to_list()\n",
        "    adm2_list += geemap.ee_to_gdf(ee_points_adm2)[\"mean\"].to_list()\n",
        "\n",
        "df_crop_type[\"ADM1_CODE\"] = adm1_list\n",
        "df_crop_type[\"ADM2_CODE\"] = adm2_list"
      ],
      "metadata": {
        "id": "oQBPaUWdLeUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_crop_type[\"ADM1_CODE\"].value_counts()"
      ],
      "metadata": {
        "id": "lkjt59k-MWkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_crop_type[\"ADM2_CODE\"].value_counts()"
      ],
      "metadata": {
        "id": "87LgwFlPMabv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Create KMZ file"
      ],
      "metadata": {
        "id": "XH4t_u1SMkG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import simplekml\n",
        "\n",
        "# Use following format: <Country>_ADM1_<ADM1 CODE>_ADM2_<ADM2 CODE>\n",
        "PREFIX = \"Kenya_ADM1_51331_ADM2_51386\""
      ],
      "metadata": {
        "id": "9F5fUCHgMv7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint_prefix = STREET2SAT_UPLOADED_FOLDER.replace(\"gs://\", \"\")\n",
        "\n",
        "\n",
        "def create_description(record, image_path):\n",
        "    image_name = Path(image_path).name\n",
        "    endpoint = Path(endpoint_prefix + \"/\" + image_name)\n",
        "    name = \"-\".join(endpoint.parts[2:-1]) + \"-\" + endpoint.stem\n",
        "    return f\"\"\"\n",
        "<img src='files/{image_name}' width='900px'/>\n",
        "<br/>\n",
        "<h2>{name}</h2>\n",
        "<p>Capture Time: {record['date']}</p>\n",
        "<a href='https://storage.cloud.google.com/{endpoint}'>\n",
        "    https://storage.cloud.google.com/{endpoint}\n",
        "</a>\n",
        "\n",
        "<h2>Location</h2>\n",
        "<p>ADM1: {record['ADM1_CODE']}</p>\n",
        "<p>ADM2: {record['ADM2_CODE']}</p>\n",
        "<p>Road Lat Lon: {record['lat']}, {record['lon']}</p>\n",
        "<p>Field Lat Lon:  {record[\"offset_field_pixel_centroid\"]}</p>\n",
        "\n",
        "\n",
        "<h2>Driving Direction</h2>\n",
        "<p>Northing: {record['driving_northing']}</p>\n",
        "<p>Easting: {record['driving_easting']}</p>\n",
        "<p>Is Right Hand Drive: {record['is_right_hand_drive']}</p>\n",
        "\n",
        "<h2>CropSeg Model Prediction</h2>\n",
        "<p>{record['segmentation_proportions']}</p>\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "umpd_qNZGQkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create KMZ file for every 100 points (more points make the KMZ laggy)\n",
        "num_records = len(df_crop_type)\n",
        "\n",
        "for range_start in range(0, num_records, 100):\n",
        "    if range_start + 100 < num_records:\n",
        "        range_end = range_start + 100\n",
        "    else:\n",
        "        range_end = num_records\n",
        "\n",
        "    kml_document_name = PREFIX + f\"_95_background_{range_start}_{range_end}\"\n",
        "\n",
        "    kml = simplekml.Kml()\n",
        "    kml.document.name = kml_document_name\n",
        "\n",
        "    for _, record in tqdm(df_crop_type[range_start:range_end].iterrows()):\n",
        "        latlon = record[\"offset_field_pixel_centroid\"]\n",
        "        image_path = record['paths']\n",
        "        kml.newpoint(\n",
        "            coords=[(latlon[1], latlon[0])],  # lon, lat optional height\n",
        "            description=create_description(record, image_path),\n",
        "            name=record[\"dominant_crop\"],\n",
        "            timestamp=record[\"date\"]\n",
        "        )\n",
        "        kml.addfile(image_path)\n",
        "\n",
        "\n",
        "    kml.savekmz(f\"{kml_document_name}.kmz\", format=False)"
      ],
      "metadata": {
        "id": "uULyghOYM4nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Save the notebook\n",
        "\n",
        "1. Rename this notebook to have the name: ` <PREFIX>.ipynb`\n",
        "2. Click File / Download / Download .ipynb"
      ],
      "metadata": {
        "id": "dkkkCjuaVOBN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##11. Download KMZ files\n",
        "\n",
        "KMZ files are now prepared in the left hand tab.\n",
        "\n",
        "1. Download each KMZ file by hovering over the file, clicking the three vertical dots and clicking download.\n",
        "\n",
        "2. Conduct a Quality Assessment following this protocol:\n",
        "https://docs.google.com/document/d/1OCF2gpCQQbZP-y6xcTbKE2OzhkxMtyaJi8wiWi8jfzs/edit?usp=sharing"
      ],
      "metadata": {
        "id": "_FDozdDFUaeG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MofrQjrkOuBt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
